\documentclass[conference]{IEEEtran}
% \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\bibliographystyle{IEEEtran}

\title{Applying ResNet and Inception Module Techniques for Skin Cancer Classification on Breast Histopathology Images Dataset with Convolutional Neural Networks\\
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Pedro Almeida}
\IEEEauthorblockA{\textit{Department of Ocean \& Mechanical Engineering} \\
\textit{Florida Atlantic University}\\
Boca Raton, United States \\
palmeida2016@fau.edu}
}

\maketitle

\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
artificial neural network, machine learning, convolutional neural network
\end{IEEEkeywords}

\section{Introduction}
Over the past 40 years \cite{Fukushima1980}, the field of object detection in machine learning has made massive strides in classification and detection capabilities. In addition to the expected improvements stemming from larger datasets, deeper models, and more powerful machines, much of the advancement owes to new and improved network architectures and novel algorithms. These techniques, often designed with specific datasets in mind, take advantage of the structure of the data to optimize the amount of information extracted per layer.The difficulty in designing the networks stem from the increasingly numerous design choices in determining hyper-parameters (width\footnote{Width -- The number of channels in a layer.}, filter sizes, strides, pooling layer parameters, dropout rates, \emph{etc.}) and the large selection of techniques in constructing the network architecture \cite{Krizhevsky2012, Szegedy2014, He2016, Huang2016, Simonyan2014, Hu2017, Xie2017, huang2019convolutional, Zhao2021}.

The family of inception models \cite{Szegedy2014, Szegedy2015, Szegedy2016} tackled the problem by introducing an extra dimension cardinality: the number of independent paths within a layer. The central method employed involves splitting the input of a layer into lower-dimensional embeddings whereby each is transformed by a set of specialized filters with different kernel sizes, which are then concatenated. The \emph{split-transform-merge} method has been shown to approximate the representational power of large, dense layers, but at a substantially lower computational complexity. Despite showing good improvements in accuracy, the inception module suffers from a difficulty in tailoring filter numbers and sizes for different datasets/objectives; although the right combination can yield significant improvements to the accuracy, it is generally unclear as to how to adapt the Inception module architecture of a given problem, especially in combination with other complex transformations and hyper-parameters are involved.

Another strategy introduced by the family of ResNet models and its variants proposes the use of residual learning through stacking modules of the same topology. This simple rule creates a an effective strategy for constructing very deep network architectures that are applicable to a wide range of tasks, owing partially to the reduction of free choices for hyper-parameters.

The objective of the report is to explore the combination of some of these techniques \cite{Szegedy2014, He2016} through the Breast Histopathology Dataset \cite{Mooney2017}. The dataset contains 162 whole mount slide images of a breast cancer variant called Invasive Ductal Carcinoma scanned at forty-times magnification. As of 2019, breast cancer affects 1 in 8 \cite{DeSantis2019} women during their lifetime, registering roughly 268,600 new cases every year. Invasive Ductal Carcinoma, also known as Infiltrating Ductal Carcinoma, is the most common type breast cancer, accounting for 80\% \cite{Sharma2010} of breast cancer diagnoses. As is the case for most cancers, early detection accounts for most of successful treatments of the disease; as the cancer progresses to the later stages, the odds of spreading to nearby organs increases \cite{Milosevic2018}, thus furthering the risk of the death of the patient.

We propose a Convolutional Neural Network architecture 

\section{Related Work}
Since the introduction of Convolutional Neural Networks (CNN), the model architecture off CNNs has remained largely static: a series of convolutional layers followed by optional normalization and pooling layers and finally one or more dense layers reducing to the output. This standard architecture and its variations have reigned dominant in accurately classifying objects in small and large datasets alike, from MNIST, CIFAR, ImageNet, MS-COCO, SVHN, and others. For larger datasets especially, the latest novel idea has been the introduction of deeper networks with dropout layers to correct for overfitting.

The tradeoff for adding more layers to a network is apparent in the time to train; as the model grows in size and increases the number of weights, the backwards propagation in updating the weights takes progressively longer, thus greatly adding to the required time to train. Furthermore, although the development of newer, more powerful machines and better parallelization and multi-processing techniques can somewhat mitigate the additional computational cost.
\section{Methods}
\subsection{ResNet Layer}
The first CNN modification applied in the model architecture employs residual learning within the convolution layers. As described by He \textit{et al.} \cite{He2016}, let us consider a residual layer within a neural network defined as:

\begin{equation}
y = \mathcal{F} \left(x,\{W_i\}\right) + x
\label{residual_layer_equation}
\end{equation}

In Eq. \ref{residual_layer_equation}, $x$ and $y$ are the input and output vectors of the layer respectively. The function $\mathcal{F} \left(x,\{W_i\}\right)$ represents the mapping of inputs to outputs given a set of weights $W_i$ for each of the feature maps of the inner convolutions \cite{He2016}. For the example shown in Fig. \ref{ResNet_Layer_Model}, the input $x$ to the layer passes through 4 convolutional layers, which together constitute $\mathcal{F}(x)$ before the concatenation with the input $x$. The final concatenation of the output of the feature maps and initial input is a element-wise addition performed channel by channel, which is then passed through an activation layer. 

In the original paper by He, the residual function $\mathcal{F} \left(x,\{W_i\}\right)$ constitutes of 2-3 fully connected layers \cite{He2016}. The proposed architecture slightly alters the core ResNet model by substituting the fully connected layers by convolutional layers followed by Rectified Linear Unit -- also known as ReLU -- activation functions.

\begin{figure}
\centering
\includegraphics[width=0.3\textwidth]{figures/ResNet_Model.png}
\label{ResNet_Layer_Model}
\caption{Model of ResNet Layer with 4 Convolutions followed by concatenation.}
\end{figure}

\subsection{Inception Module Layer}
The second CNN modification applied in the network architecture is the use of the Inception Module \cite{Szegedy2014} designed by Szegedy et al. Unlike the ResNet Layer, the inception module challenges the lengthening of neural netwroks for better performance through optimal local spare structures.

\subsection{Network Architecture}
\subsection{Data Augmentation}
Each of the 162 samples in the dataset have been partitioned to create 277,524 50x50-pixel patches of which 198,738 are IDC negative and 78,786 are IDC positive. In preparation for the training cycle, tthe samples were shuffled and distributed into training, validation, and testing sets constituting 60\%, 20\%, and 20\% of the samples respectively. To account for the imbalance in negative and positive samples, the distribution executed ensures the ratio of negative to positive samples is consistent across all three datasets.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth]{figures/dataset_example.png}
\label{dataset_example}
\caption{Example of partitioned images found in dataset.}
\end{figure}

The data in each of the sections is then converted from RGB to BGR dataset for training with each color channel zero-centered. 

\subsection{Training the Network}

\section{Results}

\section{Analysis and Discussion}

\section{Conclusions}

\section*{Acknowledgment}

\bibliography{citations}

\end{document}
